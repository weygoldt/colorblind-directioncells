{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Calcium imaging in the zebrafish tectum\n",
    "description: Are direction-selective cells in the zebrafish optical tectum colorblind?\n",
    "author: 'Alexander Wendt, Patrick Weygoldt'\n",
    "date: '2018-05-04'\n",
    "date-format: long\n",
    "published-title: Date\n",
    "author-title: Authors\n",
    "title-block-banner: '#1d1d1d'\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    fig-format: svg\n",
    "    fig-responsive: true\n",
    "    theme:\n",
    "      light: flatly\n",
    "      dark: darkly\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import modules.functions as fs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.stats\n",
    "\n",
    "from copy import deepcopy\n",
    "from vxtools.summarize.structure import SummaryFile\n",
    "from modules.dataloader import MultiFish, SingleFish\n",
    "from modules.plotstyle import PlotStyle\n",
    "from sklearn.metrics import auc\n",
    "from scipy.stats import pearsonr\n",
    "from modules.contrast import selective_rois_trash, rg_activity_trash, phase_activity\n",
    "%matplotlib qt\n",
    "\n",
    "ps = PlotStyle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "\n",
    "In order to work with a datasat including all 3 fish we recorded from, we first load the SummaryFile datasets from all 3 fish and combine them using our `MultiFish` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SingleFish' object has no attribute 'eye_velocs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m d3 \u001b[39m=\u001b[39m SingleFish(f3, good_recs3, overwrite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, behav\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# load all fish in multifish class\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m mf \u001b[39m=\u001b[39m MultiFish([\n\u001b[1;32m     23\u001b[0m     d1, \n\u001b[1;32m     24\u001b[0m     d2, \n\u001b[1;32m     25\u001b[0m     d3\n\u001b[1;32m     26\u001b[0m ])\n",
      "File \u001b[0;32m~/Data/uni/neuro_gp/calciumimaging/code/modules/dataloader.py:340\u001b[0m, in \u001b[0;36mMultiFish.__init__\u001b[0;34m(self, fishes)\u001b[0m\n\u001b[1;32m    338\u001b[0m all_dffs \u001b[39m=\u001b[39m [fish\u001b[39m.\u001b[39mdffs \u001b[39mfor\u001b[39;00m fish \u001b[39min\u001b[39;00m fishes]\n\u001b[1;32m    339\u001b[0m all_zscores \u001b[39m=\u001b[39m [fish\u001b[39m.\u001b[39mzscores \u001b[39mfor\u001b[39;00m fish \u001b[39min\u001b[39;00m fishes]\n\u001b[0;32m--> 340\u001b[0m all_eye_velocs \u001b[39m=\u001b[39m [fish\u001b[39m.\u001b[39meye_velocs \u001b[39mfor\u001b[39;00m fish \u001b[39min\u001b[39;00m fishes]\n\u001b[1;32m    342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdffs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(all_dffs)\n\u001b[1;32m    343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzscores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(all_zscores)\n",
      "File \u001b[0;32m~/Data/uni/neuro_gp/calciumimaging/code/modules/dataloader.py:340\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    338\u001b[0m all_dffs \u001b[39m=\u001b[39m [fish\u001b[39m.\u001b[39mdffs \u001b[39mfor\u001b[39;00m fish \u001b[39min\u001b[39;00m fishes]\n\u001b[1;32m    339\u001b[0m all_zscores \u001b[39m=\u001b[39m [fish\u001b[39m.\u001b[39mzscores \u001b[39mfor\u001b[39;00m fish \u001b[39min\u001b[39;00m fishes]\n\u001b[0;32m--> 340\u001b[0m all_eye_velocs \u001b[39m=\u001b[39m [fish\u001b[39m.\u001b[39;49meye_velocs \u001b[39mfor\u001b[39;00m fish \u001b[39min\u001b[39;00m fishes]\n\u001b[1;32m    342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdffs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(all_dffs)\n\u001b[1;32m    343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzscores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(all_zscores)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SingleFish' object has no attribute 'eye_velocs'"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "# now load the data\n",
    "data1 = '../data/data1/'\n",
    "data2 = '../data/data2/'\n",
    "data3 = '../data/data3/'\n",
    "\n",
    "f1 = SummaryFile(data1 + 'Summary.hdf5')\n",
    "f2 = SummaryFile(data2 + 'Summary.hdf5')\n",
    "f3 = SummaryFile(data3 + 'Summary.hdf5')\n",
    "\n",
    "good_recs1 = np.arange(3,15)\n",
    "good_recs2 = [0, 1, 2, 4, 5]\n",
    "good_recs3 = [0, 1, 2, 3, 4]\n",
    "\n",
    "# load matrix of all rois of all layers with good rois\n",
    "d1 = SingleFish(f1, good_recs1, overwrite=False, behav=False)\n",
    "d2 = SingleFish(f2, good_recs2, overwrite=False, behav=True)\n",
    "d3 = SingleFish(f3, good_recs3, overwrite=False, behav=False)\n",
    "\n",
    "# load all fish in multifish class\n",
    "mf = MultiFish([\n",
    "    d1, \n",
    "    d2, \n",
    "    d3\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an overview of the dataset, we plot the zscores for every single ROI in a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "# make imshow extent and flatten data for phases in dff matrix\n",
    "extent = (mf.times.min(), mf.times.max(), 0, len(mf.zscores[:,0]))\n",
    "temp_zscores = np.asarray([fs.flatten(x) for x in mf.zscores])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30*ps.cm, 20*ps.cm), constrained_layout=True)\n",
    "ax.imshow(temp_zscores, extent=extent, aspect=\"auto\")\n",
    "ax.set_xlabel(\"time [s]\")\n",
    "ax.set_ylabel(\"ROIs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the mean zscore and dff for every ROI in every single stimulus phase window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean in each phase\n",
    "mf.phase_means()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter out ROIs that responded to stimulation, we compute the autocorrelation of a single ROI across stimulation trial repeats and threshold it using a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "target_auc = 0.2 # probability threshold\n",
    "\n",
    "# compute the correlations and indices sorted by correlations\n",
    "indices, corrs = mf.responding_rois(mf.dffs, nrepeats=3)\n",
    "\n",
    "# make a histpgram\n",
    "counts, edges = np.histogram(corrs, bins=50, range=(-1,1), density=True)\n",
    "\n",
    "# compute a gaussian KDE\n",
    "xkde, kde = fs.kde1d(corrs, 0.02, xlims=[edges.min(), edges.max()])\n",
    "\n",
    "# create empty arrays for the gradient and index\n",
    "gradient = np.zeros_like(xkde[:-1])\n",
    "index = np.arange(len(xkde[:-1]))\n",
    "\n",
    "# compute the gradient between the target and actual auc\n",
    "for i in range(len(xkde[:-1])):\n",
    "    area = auc(xkde[i:], kde[i:])\n",
    "    gradient[i] = abs(area-target_auc)\n",
    "\n",
    "# find the index where the gradient is smallest\n",
    "idx = index[gradient == gradient.min()][0]\n",
    "\n",
    "# get the threshold for correlation coefficients here\n",
    "thresh = xkde[idx]\n",
    "print(f\"{thresh=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "# plot PDF, histogram and the gradient\n",
    "fig, ax = plt.subplots(1,2,figsize=(20*ps.cm, 8*ps.cm), constrained_layout=True)\n",
    "\n",
    "ax[0].plot(xkde, kde, c=ps.c1, lw=2)\n",
    "\n",
    "ax[0].bar(\n",
    "    edges[:-1], \n",
    "    counts, \n",
    "    width=np.diff(edges),\n",
    "    edgecolor=\"darkgray\", \n",
    "    facecolor=\"white\", \n",
    "    # alpha=0.2,\n",
    "    linewidth=1, \n",
    "    align=\"edge\", \n",
    "    zorder=-20\n",
    ")\n",
    "\n",
    "ax[0].axvline([0], lw=1, ls=\"dashed\", c=\"k\")\n",
    "\n",
    "ax[0].fill_between(\n",
    "    xkde[idx:], \n",
    "    np.zeros_like(xkde[idx:]), \n",
    "    kde[idx:], \n",
    "    zorder=-10, \n",
    "    alpha=0.5, \n",
    "    color=ps.c2\n",
    ")\n",
    "\n",
    "ax[1].plot(xkde[:-1], gradient, c=ps.c1, lw=2)\n",
    "ax[1].scatter(xkde[idx], gradient[idx], zorder=10, color=ps.c2)\n",
    "ax[1].axvline(thresh, lw=1, ls=\"dashed\", c=ps.black)\n",
    "\n",
    "ax[0].set_title(\"Area under PDF\")\n",
    "ax[0].set_ylabel(\"PDF\")\n",
    "ax[1].set_title(\"Difference gradient\")\n",
    "ax[1].set_ylabel(\"AUC-thresh\")\n",
    "\n",
    "fig.supxlabel(\"Pearson r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "# only take the indices where correlation coefficients crossed the thresh\n",
    "indices_thresh = indices[corrs > thresh]\n",
    "corrs_thresh = corrs[corrs > thresh]\n",
    "\n",
    "# create the subset of the dataset for these indices\n",
    "mf.filter_rois(indices_thresh)\n",
    "\n",
    "print(f\"Old number of indices: {len(indices)}\")\n",
    "print(f\"New number of indices: {len(indices_thresh)}\")\n",
    "print(f\"Number of ROIs after thresholding: {len(mf.dffs[:,0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "# make imshow extent and flatten data for phases in dff matrix\n",
    "extent = (mf.times.min(), mf.times.max(), 0, len(mf.dffs[:,0]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30*ps.cm, 20*ps.cm), constrained_layout=True)\n",
    "ax.imshow(mf.dffs, extent=extent, aspect=\"auto\")\n",
    "ax.set_xlabel(\"time [s]\")\n",
    "ax.set_ylabel(\"ROIs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "# build motion regressor and correlate\n",
    "motion = np.array([1 if x != 0 else 0 for x in mf.ang_velocs])\n",
    "corr_motion = np.array([pearsonr(x, motion)[0] for x in mf.dffs])\n",
    "\n",
    "# clockwise motion regressor\n",
    "clock = np.array([1 if x > 0 else 0 for x in mf.ang_velocs])\n",
    "corr_clock = np.array([pearsonr(x, clock)[0] for x in mf.dffs])\n",
    "\n",
    "# counterclockwise motion regressor\n",
    "cclock = np.array([1 if x < 0 else 0 for x in mf.ang_velocs])\n",
    "corr_cclock = np.array([pearsonr(x, cclock)[0] for x in mf.dffs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(30*ps.cm, 10*ps.cm), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "histr = (-0.55, 0.55)\n",
    "\n",
    "ax[0].hist(corr_motion, bins=40, range=histr, fc=ps.c1)\n",
    "ax[0].plot([0,0], [0, 600], lw=1, linestyle='dashed', c=ps.black)\n",
    "\n",
    "ax[1].hist(corr_clock, bins=40, range=histr, fc=ps.c1)\n",
    "ax[1].plot([0,0], [0, 600], lw=1, linestyle='dashed', c=ps.black)\n",
    "\n",
    "ax[2].hist(corr_cclock, bins=40, range=histr, fc=ps.c1)\n",
    "ax[2].plot([0,0], [0, 600], lw=1, linestyle='dashed', c=ps.black)\n",
    "\n",
    "ax[0].set_title(\"motion\", y=0.9)\n",
    "ax[1].set_title(\"clockw.\", y=0.9)\n",
    "ax[2].set_title(\"counterclockw.\", y=0.9)\n",
    "\n",
    "# remove upper and right axis\n",
    "[x.spines[\"right\"].set_visible(False) for x in ax]\n",
    "[x.spines[\"top\"].set_visible(False) for x in ax]\n",
    "\n",
    "# make axes nicer\n",
    "[x.set_yticks(np.arange(0, 601, 200)) for x in ax]\n",
    "[x.spines.left.set_bounds((0, 600)) for x in ax]\n",
    "\n",
    "[x.set_xticks(np.arange(-0.6, 0.61, 0.3)) for x in ax]\n",
    "[x.spines.bottom.set_bounds((-0.6, 0.6)) for x in ax]\n",
    "\n",
    "plt.subplots_adjust(left=0.15, right=1, top=0.92, bottom=0.14, hspace=0)\n",
    "fig.supxlabel(\"Pearson r\")\n",
    "fig.supylabel(\"Count\")\n",
    "\n",
    "fs.doublesave(\"../plots/corrcoefs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "# correlation coefficient threshold\n",
    "thresh = 0.3\n",
    "\n",
    "# get index of active ROIs for correlation threshold for clockwise and \n",
    "# counterclockwise regressor correlations\n",
    "index_clock = np.arange(len(mf.dffs[:,0]))[corr_clock > thresh]\n",
    "index_cclock = np.arange(len(mf.dffs[:,0]))[corr_cclock > thresh]\n",
    "\n",
    "# create copies of dataset\n",
    "mfclock = deepcopy(mf)\n",
    "mfcclock = deepcopy(mf)\n",
    "\n",
    "# filter direction selective rois\n",
    "mfclock.filter_rois(index_clock)\n",
    "mfcclock.filter_rois(index_cclock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "# modify motion stim to remove all phases without motion\n",
    "clock = np.asarray([np.nan if x==0 else x for x in clock])\n",
    "cclock = np.asarray([np.nan if x==0 else x for x in cclock])\n",
    "\n",
    "# get achromatic contrast where motion was on\n",
    "achrom_clock = abs(mf.red-mf.green)*clock\n",
    "achrom_cclock = abs(mf.red-mf.green)*cclock\n",
    "\n",
    "# make indices and categories array\n",
    "index = np.arange(len(achrom_clock))\n",
    "categories = np.unique(achrom_clock[~np.isnan(achrom_clock)])\n",
    "\n",
    "# extract activity at different categories\n",
    "zscores_clock = []\n",
    "zscores_cclock = []\n",
    "for c in categories:\n",
    "    \n",
    "    # get index for current categories\n",
    "    idx_clock = index[achrom_clock == c]\n",
    "    idx_cclock = index[achrom_cclock == c]\n",
    "\n",
    "    # get zscores at index\n",
    "    z_clock = mfclock.zscores[:, idx_clock]\n",
    "    z_cclock = mfcclock.zscores[:, idx_cclock]\n",
    "    \n",
    "    # append to lists\n",
    "    zscores_clock.append(z_clock)    \n",
    "    zscores_cclock.append(z_cclock)\n",
    "\n",
    "\n",
    "# make plottable arrays and compute means for both\n",
    "zscores_clock_mean = np.asarray([np.mean(x) for x in zscores_clock])\n",
    "zscores_clock_std = np.asarray([np.std(x) for x in zscores_clock])\n",
    "zscores_cclock_mean = np.asarray([np.mean(x) for x in zscores_cclock])\n",
    "zscores_cclock_std = np.asarray([np.std(x) for x in zscores_cclock])\n",
    "\n",
    "# make x axis for scatterplot\n",
    "zscores_clock_mean_scatterx = fs.flatten(fs.flatten([np.full_like(x, fill_value=y) for x, y in zip(zscores_clock, categories)]))\n",
    "zscores_cclock_mean_scatterx = fs.flatten(fs.flatten([np.full_like(x, fill_value=y) for x, y in zip(zscores_cclock, categories)]))\n",
    "\n",
    "# make y axis for scatterplot\n",
    "zscores_clock_mean_scatter = fs.flatten([fs.flatten(x) for x in zscores_clock])\n",
    "zscores_cclock_mean_scatter = fs.flatten([fs.flatten(x) for x in zscores_cclock])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "# plot the response to achromatic contrasts\n",
    "fig, ax = plt.subplots(figsize=(15*ps.cm, 10*ps.cm))\n",
    "\n",
    "ax.plot(categories, zscores_clock_mean, lw=2.5, c=ps.c1, label=\"clockwise\")\n",
    "ax.fill_between(categories, zscores_clock_mean-zscores_clock_std, zscores_clock_mean+zscores_clock_std, alpha=0.2, color=ps.c1)\n",
    "\n",
    "ax.plot(categories, zscores_cclock_mean, lw=2, c=ps.c2, label=\"countercl.\")\n",
    "ax.fill_between(categories, zscores_cclock_mean-zscores_cclock_std, zscores_cclock_mean+zscores_cclock_std, alpha=0.2, color=ps.c2)\n",
    "\n",
    "fig.legend(ncols=2, bbox_to_anchor=(0.5, 0.98), loc='upper center')\n",
    "ax.set_xlabel(\"achromatic contrast\")\n",
    "ax.set_ylabel(\"z-score\")\n",
    "\n",
    "# remove upper and right axis\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "# make axes nicer\n",
    "ax.set_yticks(np.arange(-0.75, 2, 0.5))\n",
    "ax.spines.left.set_bounds((-0.75, 1.75))\n",
    "\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.25))\n",
    "ax.spines.bottom.set_bounds((0, 1))\n",
    "\n",
    "plt.subplots_adjust(left=0.15, right=1, top=0.92, bottom=0.14, hspace=0)\n",
    "fs.doublesave(\"../plots/achromatic_curves\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "class rg_activity:\n",
    "    def __init__(self, selective_rois, contr1, contr2):\n",
    "\n",
    "        self.__rois = selective_rois\n",
    "        self.__contr1 = contr1\n",
    "        self.__contr2 = contr2\n",
    "        self.__index = np.arange(len(self.__contr1))\n",
    "        self.contr1 = np.unique(self.__contr1[~np.isnan(self.__contr1)])\n",
    "        self.contr2 = np.unique(self.__contr2[~np.isnan(self.__contr2)])\n",
    "        self.zscores = []\n",
    "        # self.mean_dffs = []\n",
    "        self.contr1_index = []\n",
    "        self.contr2_index = []\n",
    "        self.rois = self.__rois.rois\n",
    "        self.recs = self.__rois.recs\n",
    "        \n",
    "        for c1 in self.contr1:\n",
    "\n",
    "            self.contr1_index.append(c1)\n",
    "            idx = self.__index[self.__contr1 == c1]\n",
    "            cat_zscores = self.__rois.zscores[:,idx]\n",
    "            # mean_dffs = np.mean(cat_dffs, axis=1)\n",
    "            self.contr2_index.append(self.__contr2[idx])\n",
    "            self.zscores.append(cat_zscores)\n",
    "            # self.mean_dffs.append(mean_dffs)\n",
    "\n",
    "        # self.mean_dffs = np.array(self.mean_dffs)\n",
    "        self.contr1_index = np.array(self.contr1_index)\n",
    "        self.contr2_index = np.array(self.contr2_index)\n",
    "\n",
    "red_clock = clock * mf.red\n",
    "green_clock = clock * mf.green\n",
    "red_cclock = cclock * mf.red\n",
    "green_cclock = cclock * mf.green\n",
    "\n",
    "rg_clock_data = rg_activity(mfclock, red_clock, green_clock)\n",
    "rg_cclock_data = rg_activity(mfcclock, red_cclock, green_cclock)\n",
    "gr_clock_data = rg_activity(mfclock, green_clock, red_clock)\n",
    "gr_cclock_data = rg_activity(mfcclock, green_cclock, red_cclock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: false\n",
    "\n",
    "# combine datasets for resampling\n",
    "bootstr_data_clock = deepcopy(mfclock)\n",
    "bootstr_data_cclock = deepcopy(mfcclock)\n",
    "\n",
    "# shuffle zscores\n",
    "for i in range(len(bootstr_data_clock.zscores[:, 0])):\n",
    "    clock_index = np.arange(len(mf.ang_velocs))[mf.ang_velocs < 0]\n",
    "    clock_data = bootstr_data_clock.zscores[i, clock_index]\n",
    "    np.random.shuffle(clock_data)\n",
    "    bootstr_data_clock.zscores[i, clock_index] = clock_data\n",
    "\n",
    "for i in range(len(bootstr_data_cclock.zscores[:, 0])):\n",
    "    cclock_index = np.arange(len(mf.ang_velocs))[mf.ang_velocs > 0]\n",
    "    cclock_data = bootstr_data_cclock.zscores[i, cclock_index]\n",
    "    print(cclock_data[:10])\n",
    "    np.random.shuffle(cclock_data)\n",
    "    print(cclock_data[:10])\n",
    "    print('')\n",
    "    bootstr_data_cclock.zscores[i, cclock_index] = cclock_data\n",
    "\n",
    "rg_bootstr_clock = rg_activity(bootstr_data_clock, red_clock, green_clock)\n",
    "rg_bootstr_cclock = rg_activity(bootstr_data_cclock, red_cclock, green_cclock)\n",
    "gr_bootstr_clock = rg_activity(bootstr_data_clock, red_clock, green_clock)\n",
    "gr_bootstr_cclock = rg_activity(bootstr_data_cclock, red_cclock, green_cclock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cclock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: false\n",
    "\n",
    "def dataconverter(data, nresamples=10000, subsetsize=0.95):\n",
    "\n",
    "    contrast1 = []\n",
    "    contrast2 = []\n",
    "    mean_zscores = []\n",
    "    std_zscores = []\n",
    "    lower_zscores = []\n",
    "    upper_zscores = []\n",
    "\n",
    "    # iterate through contrast levels\n",
    "    for it1, c1 in enumerate(data.contr1):\n",
    "        \n",
    "        # collect zscore and contrast data here\n",
    "        zscores = []\n",
    "        contrasts2 = []\n",
    "\n",
    "        # for each contrast1 level, go through all contrast2 levels\n",
    "        for zsc in np.array(data.zscores)[data.contr1 == c1]:\n",
    "\n",
    "            # go through each single ROI and append contrast levels and zscores    \n",
    "            for  roi in range(len(zsc[:,0])):\n",
    "            \n",
    "                # get the contrast2 for this specific contrast1\n",
    "                contr2 = np.array(data.contr2_index)[data.contr1 == c1][0]\n",
    "\n",
    "                # sort by contrast level\n",
    "                sort_zsc = zsc[roi, np.argsort(contr2)]\n",
    "                sort_contr2 = contr2[np.argsort(contr2)]\n",
    "\n",
    "                # append contrasts and zscore matrices\n",
    "                contrasts2.append(sort_contr2)\n",
    "                zscores.append(sort_zsc)\n",
    "\n",
    "            # for each contrast 2 category go through and compute the means and std\n",
    "            lower_zsc = []\n",
    "            upper_zsc = []\n",
    "            mean_zsc = []\n",
    "\n",
    "            contrasts2 = np.asarray(np.ravel(contrasts2))\n",
    "            zscores = np.asarray(np.ravel(zscores))\n",
    "            contr2_lvls = np.unique(contrasts2)\n",
    "        \n",
    "            for c2 in contr2_lvls:\n",
    "                \n",
    "                # compute mean and standard deviation for every c2 contrast level\n",
    "                # mean_zsc.append(np.mean(zscores[contrasts2 == c2]))\n",
    "                # std_zsc.append(np.std(zscores[contrasts2 == c2]))\n",
    "                \n",
    "                # get zscores for this condition\n",
    "                zscs = zscores[contrasts2 == c2]\n",
    "                \n",
    "                # resample them\n",
    "                sss = int(np.round(len(zscs)*subsetsize))\n",
    "                \n",
    "                # compute mean and std\n",
    "                m = np.mean(np.ravel(zscs))\n",
    "                mean_zsc.append(m)\n",
    "                # lower_zsc.append(lower)\n",
    "                # upper_zsc.append(upper)\n",
    "\n",
    "        mean_zsc = np.asarray(mean_zsc)\n",
    "        # lower_zsc = np.asarray(lower_zsc)\n",
    "        # upper_zsc = np.asarray(upper_zsc)\n",
    "\n",
    "        contrast1.append(c1)\n",
    "        contrast2.append(contr2_lvls)\n",
    "        mean_zscores.append(mean_zsc)\n",
    "        # lower_zscores.append(lower_zsc)\n",
    "        # upper_zscores.append(upper_zsc)\n",
    "# \n",
    "    contrast1 = np.asarray(contrast1)\n",
    "    contrast2 = np.asarray(contrast2)\n",
    "    mean_zscores = np.asarray(mean_zscores)\n",
    "    # lower_zscores = np.asarray(lower_zscores)\n",
    "    # upper_zscores = np.asarray(upper_zscores)\n",
    "# \n",
    "    return contrast1, contrast2, mean_zscores\n",
    "\n",
    "contrast1, contrast2, mean_zscores = dataconverter(rg_clock_data)\n",
    "\n",
    "print(np.shape(mean_zscores))\n",
    "#print(np.shape(std_zscores))\n",
    "print(np.shape(contrast1))\n",
    "print(np.shape(contrast2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(contrast2[:,0])):\n",
    "    plt.plot(contrast2[i,:], mean_zscores[i,:])\n",
    "    plt.fill_between(contrast2[i,:], lower_zscores[i,:], upper_zscores[i,:], alpha = 0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "fig = plt.figure(figsize=(30*ps.cm, 20*ps.cm))\n",
    "\n",
    "# build the subfigures\n",
    "(subfig_l, subfig_r) = fig.subfigures(1, 2, hspace=0.05, width_ratios=[1, 1])\n",
    "\n",
    "gs0 = gridspec.GridSpec(2, 3, figure=subfig_l)\n",
    "stim_axs1 = [subfig_l.add_subplot(i) for i in gs0]\n",
    "\n",
    "gs1 = gridspec.GridSpec(2, 3, figure=subfig_r)\n",
    "stim_axs2 = [subfig_r.add_subplot(i) for i in gs1]\n",
    "\n",
    "# make axes shared\n",
    "stim_axs1[0].get_shared_x_axes().join(stim_axs1[0], *stim_axs1)\n",
    "stim_axs1[0].get_shared_y_axes().join(stim_axs1[0], *stim_axs1)\n",
    "stim_axs2[0].get_shared_x_axes().join(stim_axs2[0], *stim_axs2)\n",
    "stim_axs2[0].get_shared_y_axes().join(stim_axs2[0], *stim_axs2)\n",
    "\n",
    "# plot the left side of the plot\n",
    "colors = [ps.orange, ps.red, ps.blue]\n",
    "labels = ['clockw.-selective', 'countercl.-selective', 'bootstrap']\n",
    "\n",
    "# get the data\n",
    "contrast1, contrast2, mean_zscores_c, = dataconverter(rg_clock_data)\n",
    "_, _, mean_zscores_cc, = dataconverter(rg_cclock_data)\n",
    "_, _, mean_zscores_b, = dataconverter(rg_bootstr_clock)\n",
    "\n",
    "for i, ax in enumerate(stim_axs1):\n",
    "    \n",
    "    ax.plot(contrast2[i], mean_zscores_c[i], lw=2, c=ps.red)\n",
    "    ax.plot(contrast2[i], mean_zscores_cc[i], lw=2, c=ps.orange)\n",
    "    ax.plot(contrast2[i], mean_zscores_b[i], lw=2, c=ps.blue)\n",
    "\n",
    "    # ax.fill_between(contrast2[i], lower_c[i], upper_c[i], alpha = 0.2, color=ps.red)\n",
    "    # ax.fill_between(contrast2[i], lower_cc[i], upper_cc[i], alpha = 0.2, color=ps.orange)\n",
    "    # ax.fill_between(contrast2[i], lower_b[i], upper_b[i], alpha = 0.2, color=ps.blue)\n",
    "    \n",
    "    ax.axhline(0, lw=1, ls='dashed', c='darkgray')\n",
    "\n",
    "# plot the right side of the plot\n",
    "colors = [ps.orange, ps.red, ps.blue]\n",
    "labels = ['clockw.-selective', 'countercl.-selective', 'bootstrap']\n",
    "\n",
    "# get the data\n",
    "contrast1, contrast2, mean_zscores_c, = dataconverter(gr_clock_data)\n",
    "_, _, mean_zscores_cc,  = dataconverter(gr_cclock_data)\n",
    "_, _, mean_zscores_b,  = dataconverter(gr_bootstr_clock)\n",
    "\n",
    "for i, ax in enumerate(stim_axs2):\n",
    "    \n",
    "    ax.plot(contrast2[i], mean_zscores_c[i])\n",
    "    ax.plot(contrast2[i], mean_zscores_cc[i])\n",
    "    ax.plot(contrast2[i], mean_zscores_b[i])\n",
    "\n",
    "    # ax.fill_between(contrast2[i], lower_c[i], upper_c[i], alpha = 0.2)\n",
    "    # ax.fill_between(contrast2[i], lower_cc[i], upper_cc[i], alpha = 0.2)\n",
    "    # ax.fill_between(contrast2[i], lower_b[i], upper_b[i], alpha = 0.2)\n",
    "    \n",
    "    ax.axhline(0, lw=1, ls='dashed', c='darkgray')\n",
    "\n",
    "# remove axes on right and top of plots\n",
    "[x.spines[\"right\"].set_visible(False) for x in np.asarray(stim_axs1)]\n",
    "[x.spines[\"top\"].set_visible(False) for x in np.asarray(stim_axs1)]\n",
    "[x.spines[\"right\"].set_visible(False) for x in np.asarray(stim_axs2)]\n",
    "[x.spines[\"top\"].set_visible(False) for x in np.asarray(stim_axs2)]\n",
    "\n",
    "# turn y axes off where not needed\n",
    "yaxes_off = [1,2,4,5]\n",
    "[x.get_yaxis().set_visible(False) for x in np.asarray(stim_axs1)[yaxes_off]]\n",
    "[x.get_yaxis().set_visible(False) for x in np.asarray(stim_axs2)[yaxes_off]]\n",
    "[x.spines[\"left\"].set_visible(False) for x in np.asarray(stim_axs1)[yaxes_off]]\n",
    "[x.spines[\"left\"].set_visible(False) for x in np.asarray(stim_axs2)[yaxes_off]]\n",
    "\n",
    "# turn x axes off where they are not needed\n",
    "xaxes_off = [0,1,2]\n",
    "[x.get_xaxis().set_visible(False) for x in np.asarray(stim_axs1)[xaxes_off]]\n",
    "[x.get_xaxis().set_visible(False) for x in np.asarray(stim_axs2)[xaxes_off]]\n",
    "[x.spines[\"bottom\"].set_visible(False) for x in np.asarray(stim_axs1)[xaxes_off]]\n",
    "[x.spines[\"bottom\"].set_visible(False) for x in np.asarray(stim_axs2)[xaxes_off]]\n",
    "\n",
    "# set all axes to same tick ranges\n",
    "x_range = np.arange(0,1.5,0.5)\n",
    "y_range = np.arange(-1,2.1,1)\n",
    "[x.set_yticks(y_range) for x in np.asarray(stim_axs1)]\n",
    "[x.set_xticks(x_range) for x in np.asarray(stim_axs1)]\n",
    "[x.set_yticks(y_range) for x in np.asarray(stim_axs2)]\n",
    "[x.set_xticks(x_range) for x in np.asarray(stim_axs2)]\n",
    "\n",
    "# set bounds to make axes nicer\n",
    "x_bounds = (0,1)\n",
    "y_bounds = (-1,2)\n",
    "[x.spines.left.set_bounds(y_bounds) for x in np.asarray(stim_axs1)]\n",
    "[x.spines.bottom.set_bounds(x_bounds) for x in np.asarray(stim_axs1)]\n",
    "[x.spines.left.set_bounds(y_bounds) for x in np.asarray(stim_axs2)]\n",
    "[x.spines.bottom.set_bounds(x_bounds) for x in np.asarray(stim_axs2)]\n",
    "\n",
    "# make axes shared\n",
    "stim_axs1[0].get_shared_x_axes().join(stim_axs1[0], *stim_axs1)\n",
    "stim_axs1[0].get_shared_y_axes().join(stim_axs1[0], *stim_axs1)\n",
    "stim_axs2[0].get_shared_x_axes().join(stim_axs2[0], *stim_axs2)\n",
    "stim_axs2[0].get_shared_y_axes().join(stim_axs2[0], *stim_axs2)\n",
    "\n",
    "# add labels\n",
    "subfig_l.supylabel('z-score')\n",
    "subfig_l.supxlabel('green contrast')\n",
    "subfig_r.supxlabel('red contrast')\n",
    "\n",
    "# get legend handles\n",
    "handles1, labels1 = stim_axs1[i].get_legend_handles_labels()\n",
    "handles2, labels2 = stim_axs2[i].get_legend_handles_labels()\n",
    "\n",
    "# add legends\n",
    "subfig_l.legend(handles1, labels1, loc='upper center', ncol=2)\n",
    "subfig_r.legend(handles2, labels2, loc='upper center', ncol=2)\n",
    "\n",
    "# adjust margins\n",
    "plt.subplots_adjust(left=0.175, right=0.975, top=0.87, bottom=0.1, hspace=0.17, wspace=0.15)\n",
    "fs.doublesave(\"../plots/contrast_curves\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the stimulus\n",
    "reds = np.round(np.geomspace(0.1, 1, 5), 2)\n",
    "reds = np.append(0, reds)\n",
    "greens = np.round(np.geomspace(0.1, 1, 5), 2)\n",
    "greens = np.append(0, greens)\n",
    "r_rgb = [np.array([r, 0, 0]) for r in reds]\n",
    "g_rgb = [np.array([0, g, 0]) for g in greens]\n",
    "rgb_matrix = np.zeros((len(r_rgb), len(g_rgb)), dtype=((float, 3), 2))\n",
    "\n",
    "for i1 in range(len(rgb_matrix[:, 0])):\n",
    "    g = g_rgb[i1]\n",
    "\n",
    "    for i2 in range(len(rgb_matrix[0, :])):\n",
    "        r = r_rgb[i2]\n",
    "        rg_rgb = [g, r]\n",
    "        rgb_matrix[i1, i2] = rg_rgb\n",
    "\n",
    "dim = np.shape(rgb_matrix)\n",
    "rgb_matrix_flat = rgb_matrix.reshape(dim[0]*dim[1], dim[2], dim[3])\n",
    "fill_r = [[0, 2], [1, 3]]\n",
    "fill_g = [[1, 3], [2, 4]]\n",
    "\n",
    "# gridspec inside gridspec\n",
    "fig = plt.figure(figsize=(20*ps.cm, 10*ps.cm))\n",
    "gs0 = gridspec.GridSpec(1, 2, figure=fig)\n",
    "\n",
    "# axes for stimulus\n",
    "gs00 = gs0[0].subgridspec(6, 6)\n",
    "stim_axs = [fig.add_subplot(i) for i in gs00]\n",
    "\n",
    "# axis for heatmap\n",
    "gs01 = gs0[1].subgridspec(1, 1)\n",
    "heatm_ax = fig.add_subplot(gs01[0])\n",
    "\n",
    "# plot the stimulus\n",
    "for axis, rgbs in zip(np.array(stim_axs).flat, rgb_matrix_flat):\n",
    "    for i in range(len(fill_r)):\n",
    "        axis.axvspan(fill_r[0][i], fill_r[1][i], color=rgbs[0])\n",
    "        axis.axvspan(fill_g[0][i], fill_g[1][i], color=rgbs[1])\n",
    "        axis.axis('off')\n",
    "\n",
    "# plot the heatmap\n",
    "# >>> DISCLAIMER this cell can probably be made much nicer but its half past 10 on a saturday\n",
    "\n",
    "def unique_combinations2d(list1, list2):\n",
    "    \"\"\"Combine elments of two lists uniquely.\"\"\"\n",
    "    return [(x, y) for x in list1 for y in list2]\n",
    "\n",
    "reds = np.unique(mf.red)\n",
    "greens = np.unique(mf.green)\n",
    "combs = unique_combinations2d(reds, greens)\n",
    "index = np.arange(len(mf.red))\n",
    "matrix = np.full((6,6), np.nan)\n",
    "\n",
    "signal1 = []\n",
    "signal2 = []\n",
    "for comb in combs:\n",
    "    \n",
    "    loc = index[(mf.red==comb[0]) & (mf.green==comb[1])]\n",
    "    \n",
    "    signal1.append(mfclock.zscores[:,loc])\n",
    "    signal2.append(mfcclock.zscores[:,loc])\n",
    "\n",
    "signal1 = np.mean(np.mean(signal1, axis=1), axis=1)\n",
    "signal2 = np.mean(np.mean(signal2, axis=1), axis=1)\n",
    "signal = np.mean(np.array([signal1, signal2]), axis=0)\n",
    "\n",
    "# put into matrix\n",
    "for i,s in enumerate(signal):\n",
    "    idx = np.unravel_index(i, np.shape(matrix))\n",
    "    matrix[idx] = s\n",
    "\n",
    "hm = heatm_ax.imshow(matrix, interpolation=\"none\", vmin=-0.2, vmax=0.2)\n",
    "heatm_ax.set_xlabel('green contr.')\n",
    "heatm_ax.set_ylabel('red contr.')\n",
    "\n",
    "cbar = fig.colorbar(hm, ax=heatm_ax, shrink=0.7)\n",
    "cbar.ax.set_ylabel('mean z-score')\n",
    "plt.subplots_adjust(left=0.015, right=0.945, top=0.960, bottom=0.045, hspace=0.250, wspace=0.200)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e65e7c3bb8f4cd8ac4466211b53c2585547d1a3ad2ae823f41b00d31837db2fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
