---
title: "Finding active ROIs"
format:
  html:
    code-fold: false
    theme:
        light: flatly
        dark: darkly
jupyter: python3
---

```{python}
# load essential packages
import matplotlib.pyplot as plt
import numpy as np
import modules.functions as fs

from vxtools.summarize.structure import SummaryFile
from sklearn.metrics import auc
from scipy.stats import spearmanr
from modules.dataloader import all_rois
from modules.plotstyle import PlotStyle

ps = PlotStyle()
```

## Importing the data

To filter all ROIs for the ones that reacted to our stimulus, we first have to load the data.

```{python}
# now load the data
f = SummaryFile('../data/Summary.hdf5')

# now select the recordings that were good
good_recs = [5, 8, 9, 10, 11, 13, 14]

# load matrix of all rois of all layers with good rois
d = all_rois(f, good_recs)
```

As described in the [loading_data](loading_data.qmd) notebook, we can now compute the means for all dff time series in each stimulation window.

```{python}
d.stimulus_means()
```

## Computing autocorrelation

Now we can compute the autocorrelation of each time series to quantify how well a cell (i.e. a single ROI) responds to the stimulation - and sort the ROIs by their correlation coefficient.

```{python}
d.sort_means_by_corr()
```

Now that we have the correlation coefficients, we can sort all ROIs in out dataset (i.e. all dffs) by their correlation coefficient.

```{python}
d.mean_dffs = np.array([d.mean_dffs[int(roi)] for roi in d.metaindex])
```

## Thresholding the autocorrelation

We use the means for each stimulation phase since the temporal resolution is not needed at this point and it is much easier to work with the means.

Before we threshold the autocorrelation, we look at a distribution of them by computing a histogram and estimate the probability density function using a gaussian kernel.

```{python}
# make a histpgram
counts, edges = np.histogram(d.corrs[:, 1], bins=50, density=True)

# compute a gaussian KDE
xkde, kde = fs.kde1d(d.corrs[:, 1], 0.02, xlims=[edges.min(), edges.max()])
```

Now we plot the results.

```{python}
#| code-fold: true
fig, ax = plt.subplots(figsize=(14*ps.cm, 6*ps.cm))
ax.bar(edges[:-1], counts, width=np.diff(edges),edgecolor="white", facecolor="k", alpha=0.2,linewidth=0, align="edge", zorder=20)
ax.plot(xkde, kde, zorder=10, c="k")
ax.axvline([0], lw=1, ls="dashed", c="k")
ax.set_xlabel("Spearman correlation")
ax.set_ylabel("Probability density")
```

Instead of implementing a fixed correlation coefficient as a threshold, we can instead use an integral of the proabability density function, to get the correlation coefficients that occur with a probability of $\alpha = 0.05$ or less.

Since we are only insterested in strong positive correlations, we can integrate (compute the area under curve, the AUC)between a value on the x axis and the maximum correlation coefficient.

```{python}
target_auc = 0.05 # probability threshold

# create empty arrays for the gradient and index
gradient = np.zeros_like(xkde[:-1])
index = np.arange(len(xkde[:-1]))

# compute the gradient between the target and actual auc
for i in range(len(xkde[:-1])):
    area = auc(xkde[i:], kde[i:])
    gradient[i] = abs(area-target_auc)

# find the index where the gradient is smallest
idx = index[gradient == gradient.min()][0]

```

```{python}
#| code-fold: true
# plot the gradient
fig, ax = plt.subplots(1,2,figsize=(20*ps.cm, 6*ps.cm), constrained_layout=True)
ax[0].plot(xkde, kde, c="k")
ax[0].fill_between(xkde[idx:], np.zeros_like(xkde[idx:]), kde[idx:], zorder=-10, alpha=0.8)
ax[0].set_title("Area under PDF")
ax[0].set_ylabel("PDF")
ax[1].plot(xkde[:-1], gradient, c="k")
ax[1].scatter(xkde[idx], gradient[idx], zorder=10)
ax[1].set_title("Difference gradient")
ax[1].set_ylabel("AUC-thresh")
fig.supxlabel("Spearman correlation", fontsize=14)
```

The correlation threshold is now the value on the x-axis at the computed index.

```{python}
thresh = xkde[idx]
```

Now we can use this value to threshold the correlations and return the dffs for the "active" ROIs. 

Before we do this, we first compute the means for a single time series across trials. This is the data which we will continue to use to narrow down a cells selectivity. Using the means across repeats emphasized correlated activity and smoothes randomness.

In a next step, we get the dffs for these ROIs.

```{python}
# get the rois
d.thresh_mean_rois = fs.thresh_correlations(d.corrs, thresh)

# compute mean across trials
d.repeat_means()

# get the dffs
d.active_meanmean_dffs = np.array([d.meanstack_mean_dffs[int(roi), :] for roi in d.thresh_mean_rois[:,0]])
```

Now lets plot a raster plot of our thresholded data.

```{python}
#| code-fold: true
fig, ax = plt.subplots(figsize=(24*ps.cm, 16*ps.cm))

extent = (np.min(d.meanstack_mean_times), np.max(d.meanstack_mean_times), 0, len(d.active_meanmean_dffs))

ax.imshow(d.active_meanmean_dffs, cmap="binary", aspect="auto", extent=extent, origin="upper", interpolation="none")

ax.set_xlabel("Time [s]")
ax.set_ylabel("ROI")
```

We already see some repeated activity but now we want to narrow it down further to get cells that reacted to (i.e. are correlated with) some feature of the stimulus, such as motion direction and / or contrasts.

## Finding motion selective cells

To find selective cells, we first need to build a regressor from the stimulus data. As a first step, we build a regressor for **motion**, **counterclockwise rotation** and **clockwise rotation**.

```{python}
# take only first repeat
idx = np.arange(d.inx_mean[0][0], d.inx_mean[0][1])

# motion regressor
motion = np.array([1 if x != 0 else 0 for x in d.ang_velocs])[idx]

# clockwise motion regressor
clock = np.array([1 if x > 0 else 0 for x in d.ang_velocs])[idx]

# counterclockwise motion regressor
cclock = np.array([1 if x < 0 else 0 for x in d.ang_velocs])[idx]
```

We now have arrays that we can use to correlate with our calcium activity, i.e. the dffs for each ROI.

```{python}
corr_motion = np.array([spearmanr(x, motion)[0] for x in d.active_meanmean_dffs])

corr_clock = np.array([spearmanr(x, clock)[0] for x in d.active_meanmean_dffs])

corr_cclock = np.array([spearmanr(x, cclock)[0] for x in d.active_meanmean_dffs])
```

Now we can plot the distribution of the correlation coefficients.

```{python}
#| code-fold: true
fig, ax = plt.subplots(1,3, figsize=(20*ps.cm, 10*ps.cm), sharex=True, sharey=True, constrained_layout=True)
ax[0].hist(corr_motion, bins=40, range=(-0.6,0.6))
ax[1].hist(corr_clock, bins=40, range=(-0.6,0.6))
ax[2].hist(corr_cclock, bins=40, range=(-0.6,0.6))
ax[0].set_title("motion")
ax[1].set_title("clockw.")
ax[2].set_title("counterclockw.")
fig.supxlabel("Spearman correlation", fontsize=14)
fig.supylabel("Count", fontsize=14)
```